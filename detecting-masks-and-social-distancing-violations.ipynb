{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:36.505996Z",
     "iopub.status.busy": "2020-11-13T15:54:36.505262Z",
     "iopub.status.idle": "2020-11-13T15:54:37.120196Z",
     "shell.execute_reply": "2020-11-13T15:54:37.120695Z"
    },
    "papermill": {
     "duration": 0.6384,
     "end_time": "2020-11-13T15:54:37.120849",
     "exception": false,
     "start_time": "2020-11-13T15:54:36.482449",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true,
    "papermill": {
     "duration": 0.014926,
     "end_time": "2020-11-13T15:54:37.149853",
     "exception": false,
     "start_time": "2020-11-13T15:54:37.134927",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using haar cascade to detect faces\n",
    "Object Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images.\n",
    "We'll be using a Haar Cascade Model trained to detect faces in order to obtain the bounding box coordinates of faces in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:37.184310Z",
     "iopub.status.busy": "2020-11-13T15:54:37.183521Z",
     "iopub.status.idle": "2020-11-13T15:54:37.219143Z",
     "shell.execute_reply": "2020-11-13T15:54:37.219936Z"
    },
    "papermill": {
     "duration": 0.055323,
     "end_time": "2020-11-13T15:54:37.220060",
     "exception": false,
     "start_time": "2020-11-13T15:54:37.164737",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ERROR:0@26.472] global /Users/runner/work/opencv-python/opencv-python/opencv/modules/core/src/persistence.cpp (505) open Can't open file: '../input/haar-cascades-for-face-detection/haarcascade_frontalface_default.xml' in read mode\n"
     ]
    }
   ],
   "source": [
    "#loading haarcascade_frontalface_default.xml\n",
    "face_model = cv2.CascadeClassifier('../input/haar-cascades-for-face-detection/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:37.254622Z",
     "iopub.status.busy": "2020-11-13T15:54:37.253944Z",
     "iopub.status.idle": "2020-11-13T15:54:38.540601Z",
     "shell.execute_reply": "2020-11-13T15:54:38.541090Z"
    },
    "papermill": {
     "duration": 1.307645,
     "end_time": "2020-11-13T15:54:38.541238",
     "exception": false,
     "start_time": "2020-11-13T15:54:37.233593",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.857] global /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('../input/face-mask-detection/images/maksssksksss244.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#trying it out on a sample image\u001B[39;00m\n\u001B[1;32m      3\u001B[0m img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../input/face-mask-detection/images/maksssksksss244.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcvtColor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mIMREAD_GRAYSCALE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m faces \u001B[38;5;241m=\u001B[39m face_model\u001B[38;5;241m.\u001B[39mdetectMultiScale(img) \u001B[38;5;66;03m#returns a list of (x,y,w,h) tuples\u001B[39;00m\n\u001B[1;32m      9\u001B[0m out_img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(img, cv2\u001B[38;5;241m.\u001B[39mCOLOR_RGB2BGR) \u001B[38;5;66;03m#colored output image\u001B[39;00m\n",
      "\u001B[0;31merror\u001B[0m: OpenCV(4.6.0) /Users/runner/work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#trying it out on a sample image\n",
    "img = cv2.imread('../input/face-mask-detection/images/maksssksksss244.png')\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "faces = face_model.detectMultiScale(img) #returns a list of (x,y,w,h) tuples\n",
    "\n",
    "out_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n",
    "\n",
    "#plotting\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(out_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020772,
     "end_time": "2020-11-13T15:54:38.586577",
     "exception": false,
     "start_time": "2020-11-13T15:54:38.565805",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Detecting social distancing violations\n",
    "This can be done by iterating over the coordinates of faces and calculating the distance for each possible pair, if the distance for a particular pair is less than MIN_DISTANCE then the bounding boxes for those faces are colored red.\n",
    "MIN_DISTANCE must be manually initialized in such a way that it corresponds to the minimum allowable distance in real life (ex. 6ft in India)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:38.637250Z",
     "iopub.status.busy": "2020-11-13T15:54:38.636420Z",
     "iopub.status.idle": "2020-11-13T15:54:38.639498Z",
     "shell.execute_reply": "2020-11-13T15:54:38.638948Z"
    },
    "papermill": {
     "duration": 0.030594,
     "end_time": "2020-11-13T15:54:38.639602",
     "exception": false,
     "start_time": "2020-11-13T15:54:38.609008",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MIN_DISTANCE = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:38.699518Z",
     "iopub.status.busy": "2020-11-13T15:54:38.698577Z",
     "iopub.status.idle": "2020-11-13T15:54:39.035985Z",
     "shell.execute_reply": "2020-11-13T15:54:39.036488Z"
    },
    "papermill": {
     "duration": 0.374878,
     "end_time": "2020-11-13T15:54:39.036625",
     "exception": false,
     "start_time": "2020-11-13T15:54:38.661747",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if len(faces)>=2:\n",
    "    label = [0 for i in range(len(faces))]\n",
    "    for i in range(len(faces)-1):\n",
    "        for j in range(i+1, len(faces)):\n",
    "            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n",
    "            if dist<MIN_DISTANCE:\n",
    "                label[i] = 1\n",
    "                label[j] = 1\n",
    "    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n",
    "    for i in range(len(faces)):\n",
    "        (x,y,w,h) = faces[i]\n",
    "        if label[i]==1:\n",
    "            cv2.rectangle(new_img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        else:\n",
    "            cv2.rectangle(new_img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(new_img)\n",
    "            \n",
    "else:\n",
    "    print(\"No. of faces detected is less than 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029461,
     "end_time": "2020-11-13T15:54:39.095910",
     "exception": false,
     "start_time": "2020-11-13T15:54:39.066449",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using mobilenet_v2 for mask detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:39.159974Z",
     "iopub.status.busy": "2020-11-13T15:54:39.159345Z",
     "iopub.status.idle": "2020-11-13T15:54:45.128590Z",
     "shell.execute_reply": "2020-11-13T15:54:45.127504Z"
    },
    "papermill": {
     "duration": 6.004181,
     "end_time": "2020-11-13T15:54:45.128729",
     "exception": false,
     "start_time": "2020-11-13T15:54:39.124548",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:45.200910Z",
     "iopub.status.busy": "2020-11-13T15:54:45.200005Z",
     "iopub.status.idle": "2020-11-13T15:54:46.969302Z",
     "shell.execute_reply": "2020-11-13T15:54:46.969807Z"
    },
    "papermill": {
     "duration": 1.811589,
     "end_time": "2020-11-13T15:54:46.969939",
     "exception": false,
     "start_time": "2020-11-13T15:54:45.158350",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#augmentation\n",
    "train_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Train'\n",
    "test_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Test'\n",
    "val_dir = '../input/face-mask-12k-images-dataset/Face Mask Dataset/Validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "val_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = train_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:47.039090Z",
     "iopub.status.busy": "2020-11-13T15:54:47.038452Z",
     "iopub.status.idle": "2020-11-13T15:54:52.120226Z",
     "shell.execute_reply": "2020-11-13T15:54:52.119408Z"
    },
    "papermill": {
     "duration": 5.120588,
     "end_time": "2020-11-13T15:54:52.120337",
     "exception": false,
     "start_time": "2020-11-13T15:54:46.999749",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mobilenet = MobileNetV2(weights='imagenet',include_top=False,input_shape=(128,128,3))\n",
    "for layer in mobilenet.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential()\n",
    "model.add(mobilenet)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:54:52.202954Z",
     "iopub.status.busy": "2020-11-13T15:54:52.201927Z",
     "iopub.status.idle": "2020-11-13T15:55:43.768792Z",
     "shell.execute_reply": "2020-11-13T15:55:43.768229Z"
    },
    "papermill": {
     "duration": 51.616829,
     "end_time": "2020-11-13T15:55:43.768916",
     "exception": false,
     "start_time": "2020-11-13T15:54:52.152087",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics =\"accuracy\")\n",
    "history = model.fit_generator(generator=train_generator,steps_per_epoch=len(train_generator)//32,epochs=20,validation_data=val_generator,validation_steps=len(val_generator)//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:55:44.069751Z",
     "iopub.status.busy": "2020-11-13T15:55:44.068465Z",
     "iopub.status.idle": "2020-11-13T15:55:50.626642Z",
     "shell.execute_reply": "2020-11-13T15:55:50.626018Z"
    },
    "papermill": {
     "duration": 6.73667,
     "end_time": "2020-11-13T15:55:50.626755",
     "exception": false,
     "start_time": "2020-11-13T15:55:43.890085",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:55:50.843723Z",
     "iopub.status.busy": "2020-11-13T15:55:50.842696Z",
     "iopub.status.idle": "2020-11-13T15:55:51.037688Z",
     "shell.execute_reply": "2020-11-13T15:55:51.038216Z"
    },
    "papermill": {
     "duration": 0.305798,
     "end_time": "2020-11-13T15:55:51.038364",
     "exception": false,
     "start_time": "2020-11-13T15:55:50.732566",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_mask_img = cv2.imread('../input/face-mask-12k-images-dataset/Face Mask Dataset/Test/WithMask/1565.png')\n",
    "sample_mask_img = cv2.resize(sample_mask_img,(128,128))\n",
    "plt.imshow(sample_mask_img)\n",
    "sample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\n",
    "sample_mask_img = sample_mask_img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:55:51.268133Z",
     "iopub.status.busy": "2020-11-13T15:55:51.267241Z",
     "iopub.status.idle": "2020-11-13T15:55:52.087217Z",
     "shell.execute_reply": "2020-11-13T15:55:52.086663Z"
    },
    "papermill": {
     "duration": 0.935883,
     "end_time": "2020-11-13T15:55:52.087346",
     "exception": false,
     "start_time": "2020-11-13T15:55:51.151463",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(sample_mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:55:52.376152Z",
     "iopub.status.busy": "2020-11-13T15:55:52.365789Z",
     "iopub.status.idle": "2020-11-13T15:55:52.604382Z",
     "shell.execute_reply": "2020-11-13T15:55:52.603389Z"
    },
    "papermill": {
     "duration": 0.39267,
     "end_time": "2020-11-13T15:55:52.604508",
     "exception": false,
     "start_time": "2020-11-13T15:55:52.211838",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save('masknet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.107757,
     "end_time": "2020-11-13T15:55:52.821793",
     "exception": false,
     "start_time": "2020-11-13T15:55:52.714036",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Integrating with haar cascade\n",
    "We now take crops of the faces detected in the image and use the model trained in the above section to determine whether the individual faces have a mask or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:55:53.044455Z",
     "iopub.status.busy": "2020-11-13T15:55:53.043733Z",
     "iopub.status.idle": "2020-11-13T15:55:53.048020Z",
     "shell.execute_reply": "2020-11-13T15:55:53.047556Z"
    },
    "papermill": {
     "duration": 0.118476,
     "end_time": "2020-11-13T15:55:53.048129",
     "exception": false,
     "start_time": "2020-11-13T15:55:52.929653",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mask_label = {0:'MASK',1:'NO MASK'}\n",
    "dist_label = {0:(0,255,0),1:(255,0,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T15:55:53.285689Z",
     "iopub.status.busy": "2020-11-13T15:55:53.284633Z",
     "iopub.status.idle": "2020-11-13T15:55:53.730086Z",
     "shell.execute_reply": "2020-11-13T15:55:53.730635Z"
    },
    "papermill": {
     "duration": 0.57291,
     "end_time": "2020-11-13T15:55:53.730771",
     "exception": false,
     "start_time": "2020-11-13T15:55:53.157861",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if len(faces)>=2:\n",
    "    label = [0 for i in range(len(faces))]\n",
    "    for i in range(len(faces)-1):\n",
    "        for j in range(i+1, len(faces)):\n",
    "            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n",
    "            if dist<MIN_DISTANCE:\n",
    "                label[i] = 1\n",
    "                label[j] = 1\n",
    "    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n",
    "    for i in range(len(faces)):\n",
    "        (x,y,w,h) = faces[i]\n",
    "        crop = new_img[y:y+h,x:x+w]\n",
    "        crop = cv2.resize(crop,(128,128))\n",
    "        crop = np.reshape(crop,[1,128,128,3])/255.0\n",
    "        mask_result = model.predict(crop)\n",
    "        cv2.putText(new_img,mask_label[mask_result.argmax()],(x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n",
    "        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],2)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(new_img)\n",
    "            \n",
    "else:\n",
    "    print(\"No. of faces detected is less than 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.117338,
     "end_time": "2020-11-13T15:55:53.964435",
     "exception": false,
     "start_time": "2020-11-13T15:55:53.847097",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1 align='center'>Thanks for reading</h1>\n",
    "<div align='center'> for implementation of this code on live cam videos check out <a href=\"https://github.com/giwilorjelly/AI-Social-Distancing-with-Mask-Detecion\"> this repository</a> </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 83.968356,
   "end_time": "2020-11-13T15:55:55.941703",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-13T15:54:31.973347",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}